models:
  TransformerPredictor:
    d_model: 192
    n_head: 8
    dim_feedforward: 512
    dropout: 0.1
    layer_norm_eps: !!float 1e-5
    norm_first: True
    batch_first: True
    num_layers: 2
    num_classes: 250
    learning_rate: 0.001
  LSTMPredictor:
    input_dim: 192
    hidden_dim: 100
    layer_dim: 5
    output_dim: 250
    learning_rate: 0.001
