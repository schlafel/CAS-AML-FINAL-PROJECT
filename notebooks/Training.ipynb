{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5934f69f-85c2-4ede-b1b2-5d5862596eb7",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "049fbbf8-8de2-4106-b634-7eb1f57e8213",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, '../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3612dfe5-c23a-4a6d-b0ae-b9d82a1e33f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "from dataset import ASL_DATASET, label_dict_inference, label_dict\n",
    "from data_utils import create_data_loaders\n",
    "from models import LSTM_BASELINE_Model\n",
    "from training import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4badcaf8-c74b-472c-8d00-fa9c93ba88ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f598cab8-afc2-4fb3-8c3f-96bc97cb92ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started\n",
      "    Mode          : cuda\n",
      "    Model type    : <class 'models.LSTM_BASELINE_Model'>\n",
      "Epoch 1\n",
      " Epoch:  1  Batch:  50 / 381  loss: 5.5214  Average batch time: 0.472 secs\n",
      " Epoch:  1  Batch: 100 / 381  loss: 5.5200  Average batch time: 0.458 secs\n",
      " Epoch:  1  Batch: 150 / 381  loss: 5.5192  Average batch time: 0.508 secs\n",
      " Epoch:  1  Batch: 200 / 381  loss: 5.5188  Average batch time: 0.595 secs\n",
      " Epoch:  1  Batch: 250 / 381  loss: 5.5182  Average batch time: 0.639 secs\n",
      " Epoch:  1  Batch: 300 / 381  loss: 5.5175  Average batch time: 0.671 secs\n",
      " Epoch:  1  Batch: 350 / 381  loss: 5.5169  Average batch time: 0.693 secs\n",
      "\n",
      "Training loss: 5.516284\n",
      "Time elapsed: 4.5 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.5127\n",
      "Epoch 2\n",
      " Epoch:  2  Batch:  50 / 381  loss: 5.5104  Average batch time: 0.439 secs\n",
      " Epoch:  2  Batch: 100 / 381  loss: 5.5099  Average batch time: 0.444 secs\n",
      " Epoch:  2  Batch: 150 / 381  loss: 5.5079  Average batch time: 0.437 secs\n",
      " Epoch:  2  Batch: 200 / 381  loss: 5.5080  Average batch time: 0.449 secs\n",
      " Epoch:  2  Batch: 250 / 381  loss: 5.5080  Average batch time: 0.449 secs\n",
      " Epoch:  2  Batch: 300 / 381  loss: 5.5079  Average batch time: 0.445 secs\n",
      " Epoch:  2  Batch: 350 / 381  loss: 5.5076  Average batch time: 0.443 secs\n",
      "\n",
      "Training loss: 5.507884\n",
      "Time elapsed: 7.5 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.5064\n",
      "Epoch 3\n",
      " Epoch:  3  Batch:  50 / 381  loss: 5.5033  Average batch time: 0.441 secs\n",
      " Epoch:  3  Batch: 100 / 381  loss: 5.5042  Average batch time: 0.443 secs\n",
      " Epoch:  3  Batch: 150 / 381  loss: 5.5040  Average batch time: 0.438 secs\n",
      " Epoch:  3  Batch: 200 / 381  loss: 5.5045  Average batch time: 0.448 secs\n",
      " Epoch:  3  Batch: 250 / 381  loss: 5.5044  Average batch time: 0.448 secs\n",
      " Epoch:  3  Batch: 300 / 381  loss: 5.5040  Average batch time: 0.445 secs\n",
      " Epoch:  3  Batch: 350 / 381  loss: 5.5042  Average batch time: 0.449 secs\n",
      "\n",
      "Training loss: 5.504004\n",
      "Time elapsed: 10.4 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.5039\n",
      "Epoch 4\n",
      " Epoch:  4  Batch:  50 / 381  loss: 5.5011  Average batch time: 0.435 secs\n",
      " Epoch:  4  Batch: 100 / 381  loss: 5.5017  Average batch time: 0.446 secs\n",
      " Epoch:  4  Batch: 150 / 381  loss: 5.5014  Average batch time: 0.449 secs\n",
      " Epoch:  4  Batch: 200 / 381  loss: 5.5011  Average batch time: 0.445 secs\n",
      " Epoch:  4  Batch: 250 / 381  loss: 5.5014  Average batch time: 0.448 secs\n",
      " Epoch:  4  Batch: 300 / 381  loss: 5.5020  Average batch time: 0.444 secs\n",
      " Epoch:  4  Batch: 350 / 381  loss: 5.5019  Average batch time: 0.442 secs\n",
      "\n",
      "Training loss: 5.502333\n",
      "Time elapsed: 13.3 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.5022\n",
      "Epoch 5\n",
      " Epoch:  5  Batch:  50 / 381  loss: 5.5007  Average batch time: 0.421 secs\n",
      " Epoch:  5  Batch: 100 / 381  loss: 5.5025  Average batch time: 0.432 secs\n",
      " Epoch:  5  Batch: 150 / 381  loss: 5.5020  Average batch time: 0.439 secs\n",
      " Epoch:  5  Batch: 200 / 381  loss: 5.5021  Average batch time: 0.602 secs\n",
      " Epoch:  5  Batch: 250 / 381  loss: 5.5013  Average batch time: 0.627 secs\n",
      " Epoch:  5  Batch: 300 / 381  loss: 5.5016  Average batch time: 0.646 secs\n",
      " Epoch:  5  Batch: 350 / 381  loss: 5.5013  Average batch time: 0.658 secs\n",
      "\n",
      "Training loss: 5.501082\n",
      "Time elapsed: 17.6 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.5012\n",
      "Epoch 6\n",
      " Epoch:  6  Batch:  50 / 381  loss: 5.5009  Average batch time: 0.462 secs\n",
      " Epoch:  6  Batch: 100 / 381  loss: 5.5015  Average batch time: 0.463 secs\n",
      " Epoch:  6  Batch: 150 / 381  loss: 5.5013  Average batch time: 0.475 secs\n",
      " Epoch:  6  Batch: 200 / 381  loss: 5.5008  Average batch time: 0.468 secs\n",
      " Epoch:  6  Batch: 250 / 381  loss: 5.5001  Average batch time: 0.466 secs\n",
      " Epoch:  6  Batch: 300 / 381  loss: 5.5004  Average batch time: 0.459 secs\n",
      " Epoch:  6  Batch: 350 / 381  loss: 5.5004  Average batch time: 0.452 secs\n",
      "\n",
      "Training loss: 5.500378\n",
      "Time elapsed: 20.5 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.5008\n",
      "Epoch 7\n",
      " Epoch:  7  Batch:  50 / 381  loss: 5.4942  Average batch time: 0.439 secs\n",
      " Epoch:  7  Batch: 100 / 381  loss: 5.4982  Average batch time: 0.430 secs\n",
      " Epoch:  7  Batch: 150 / 381  loss: 5.4988  Average batch time: 0.430 secs\n",
      " Epoch:  7  Batch: 200 / 381  loss: 5.4990  Average batch time: 0.424 secs\n",
      " Epoch:  7  Batch: 250 / 381  loss: 5.4993  Average batch time: 0.425 secs\n",
      " Epoch:  7  Batch: 300 / 381  loss: 5.4997  Average batch time: 0.434 secs\n",
      " Epoch:  7  Batch: 350 / 381  loss: 5.4994  Average batch time: 0.433 secs\n",
      "\n",
      "Training loss: 5.499643\n",
      "Time elapsed: 23.3 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4998\n",
      "Epoch 8\n",
      " Epoch:  8  Batch:  50 / 381  loss: 5.4999  Average batch time: 0.420 secs\n",
      " Epoch:  8  Batch: 100 / 381  loss: 5.4993  Average batch time: 0.418 secs\n",
      " Epoch:  8  Batch: 150 / 381  loss: 5.4997  Average batch time: 0.441 secs\n",
      " Epoch:  8  Batch: 200 / 381  loss: 5.4996  Average batch time: 0.440 secs\n",
      " Epoch:  8  Batch: 250 / 381  loss: 5.4994  Average batch time: 0.439 secs\n",
      " Epoch:  8  Batch: 300 / 381  loss: 5.4998  Average batch time: 0.441 secs\n",
      " Epoch:  8  Batch: 350 / 381  loss: 5.5001  Average batch time: 0.442 secs\n",
      "\n",
      "Training loss: 5.499938\n",
      "Time elapsed: 26.2 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4994\n",
      "Epoch 9\n",
      " Epoch:  9  Batch:  50 / 381  loss: 5.4978  Average batch time: 0.420 secs\n",
      " Epoch:  9  Batch: 100 / 381  loss: 5.4984  Average batch time: 0.439 secs\n",
      " Epoch:  9  Batch: 150 / 381  loss: 5.5003  Average batch time: 0.452 secs\n",
      " Epoch:  9  Batch: 200 / 381  loss: 5.5003  Average batch time: 0.450 secs\n",
      " Epoch:  9  Batch: 250 / 381  loss: 5.4995  Average batch time: 0.445 secs\n",
      " Epoch:  9  Batch: 300 / 381  loss: 5.4999  Average batch time: 0.446 secs\n",
      " Epoch:  9  Batch: 350 / 381  loss: 5.4995  Average batch time: 0.446 secs\n",
      "\n",
      "Training loss: 5.499422\n",
      "Time elapsed: 29.1 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4994\n",
      "Epoch 10\n",
      " Epoch: 10  Batch:  50 / 381  loss: 5.5026  Average batch time: 0.426 secs\n",
      " Epoch: 10  Batch: 100 / 381  loss: 5.4995  Average batch time: 0.451 secs\n",
      " Epoch: 10  Batch: 150 / 381  loss: 5.4989  Average batch time: 0.463 secs\n",
      " Epoch: 10  Batch: 200 / 381  loss: 5.4989  Average batch time: 0.461 secs\n",
      " Epoch: 10  Batch: 250 / 381  loss: 5.4996  Average batch time: 0.457 secs\n",
      " Epoch: 10  Batch: 300 / 381  loss: 5.4998  Average batch time: 0.461 secs\n",
      " Epoch: 10  Batch: 350 / 381  loss: 5.4997  Average batch time: 0.459 secs\n",
      "\n",
      "Training loss: 5.499718\n",
      "Time elapsed: 32.1 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4993\n",
      "Finished Training. Total time: 32.12934711376826 minutes.\n",
      "Best validation loss: 5.499, achieved on epoch #10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('',\n",
       " [5.516284450771302,\n",
       "  5.507883807805579,\n",
       "  5.50400398785048,\n",
       "  5.5023332255406014,\n",
       "  5.5010818433886755,\n",
       "  5.500378027988544,\n",
       "  5.499642594905663,\n",
       "  5.4999383340670365,\n",
       "  5.499421511422305,\n",
       "  5.499718213018783],\n",
       " [5.512722409289816,\n",
       "  5.5063746493795644,\n",
       "  5.503877142201299,\n",
       "  5.502201474231223,\n",
       "  5.501197732013205,\n",
       "  5.500753775886867,\n",
       "  5.49982446172963,\n",
       "  5.499379344608473,\n",
       "  5.499435715053393,\n",
       "  5.499283064966616],\n",
       " [])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asl_dataset = ASL_DATASET(augment=True)\n",
    "\n",
    "train_loader, valid_loader, test_loader = create_data_loaders(asl_dataset)\n",
    "\n",
    "from models import LSTM_BASELINE_Model\n",
    "\n",
    "model = LSTM_BASELINE_Model()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_model(model, train_loader, valid_loader, criterion, optimizer, scheduler=None, num_epochs=EPOCHS, save_freq=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d740f5a-e165-46bf-9833-51301ee8bf5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started\n",
      "    Mode          : cuda\n",
      "    Model type    : <class 'models.LSTM_BASELINE_Model'>\n",
      "Epoch 1\n",
      " Epoch:  1  Batch:  50 / 381  loss: 5.4963  Average batch time: 0.409 secs\n",
      " Epoch:  1  Batch: 100 / 381  loss: 5.4974  Average batch time: 0.412 secs\n",
      " Epoch:  1  Batch: 150 / 381  loss: 5.4974  Average batch time: 0.416 secs\n",
      " Epoch:  1  Batch: 200 / 381  loss: 5.4979  Average batch time: 0.414 secs\n",
      " Epoch:  1  Batch: 250 / 381  loss: 5.4977  Average batch time: 0.416 secs\n",
      " Epoch:  1  Batch: 300 / 381  loss: 5.4982  Average batch time: 0.421 secs\n",
      " Epoch:  1  Batch: 350 / 381  loss: 5.4988  Average batch time: 0.423 secs\n",
      "\n",
      "Training loss: 5.498456\n",
      "Time elapsed: 2.7 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4993\n",
      "Epoch 2\n",
      " Epoch:  2  Batch:  50 / 381  loss: 5.4986  Average batch time: 0.408 secs\n",
      " Epoch:  2  Batch: 100 / 381  loss: 5.4982  Average batch time: 0.418 secs\n",
      " Epoch:  2  Batch: 150 / 381  loss: 5.4967  Average batch time: 0.423 secs\n",
      " Epoch:  2  Batch: 200 / 381  loss: 5.4968  Average batch time: 0.424 secs\n",
      " Epoch:  2  Batch: 250 / 381  loss: 5.4978  Average batch time: 0.416 secs\n",
      " Epoch:  2  Batch: 300 / 381  loss: 5.4985  Average batch time: 0.415 secs\n",
      " Epoch:  2  Batch: 350 / 381  loss: 5.4987  Average batch time: 0.415 secs\n",
      "\n",
      "Training loss: 5.498543\n",
      "Time elapsed: 5.4 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4996\n",
      "Epoch 3\n",
      " Epoch:  3  Batch:  50 / 381  loss: 5.5010  Average batch time: 0.415 secs\n",
      " Epoch:  3  Batch: 100 / 381  loss: 5.5002  Average batch time: 0.405 secs\n",
      " Epoch:  3  Batch: 150 / 381  loss: 5.4991  Average batch time: 0.414 secs\n",
      " Epoch:  3  Batch: 200 / 381  loss: 5.4993  Average batch time: 0.422 secs\n",
      " Epoch:  3  Batch: 250 / 381  loss: 5.4997  Average batch time: 0.418 secs\n",
      " Epoch:  3  Batch: 300 / 381  loss: 5.4995  Average batch time: 0.417 secs\n",
      " Epoch:  3  Batch: 350 / 381  loss: 5.4995  Average batch time: 0.412 secs\n",
      "\n",
      "Training loss: 5.499835\n",
      "Time elapsed: 8.0 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4987\n",
      "Epoch 4\n",
      " Epoch:  4  Batch:  50 / 381  loss: 5.4966  Average batch time: 0.417 secs\n",
      " Epoch:  4  Batch: 100 / 381  loss: 5.4959  Average batch time: 0.406 secs\n",
      " Epoch:  4  Batch: 150 / 381  loss: 5.4965  Average batch time: 0.401 secs\n",
      " Epoch:  4  Batch: 200 / 381  loss: 5.4972  Average batch time: 0.405 secs\n",
      " Epoch:  4  Batch: 250 / 381  loss: 5.4977  Average batch time: 0.410 secs\n",
      " Epoch:  4  Batch: 300 / 381  loss: 5.4986  Average batch time: 0.408 secs\n",
      " Epoch:  4  Batch: 350 / 381  loss: 5.4989  Average batch time: 0.469 secs\n",
      "\n",
      "Training loss: 5.499004\n",
      "Time elapsed: 11.3 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4988\n",
      "Epoch 5\n",
      " Epoch:  5  Batch:  50 / 381  loss: 5.4974  Average batch time: 0.535 secs\n",
      " Epoch:  5  Batch: 100 / 381  loss: 5.4956  Average batch time: 0.514 secs\n",
      " Epoch:  5  Batch: 150 / 381  loss: 5.4958  Average batch time: 0.517 secs\n",
      " Epoch:  5  Batch: 200 / 381  loss: 5.4965  Average batch time: 0.510 secs\n",
      " Epoch:  5  Batch: 250 / 381  loss: 5.4973  Average batch time: 0.508 secs\n",
      " Epoch:  5  Batch: 300 / 381  loss: 5.4980  Average batch time: 0.511 secs\n",
      " Epoch:  5  Batch: 350 / 381  loss: 5.4982  Average batch time: 0.507 secs\n",
      "\n",
      "Training loss: 5.498706\n",
      "Time elapsed: 14.7 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4989\n",
      "Epoch 6\n",
      " Epoch:  6  Batch:  50 / 381  loss: 5.4969  Average batch time: 0.409 secs\n",
      " Epoch:  6  Batch: 100 / 381  loss: 5.4973  Average batch time: 0.401 secs\n",
      " Epoch:  6  Batch: 150 / 381  loss: 5.4968  Average batch time: 0.410 secs\n",
      " Epoch:  6  Batch: 200 / 381  loss: 5.4972  Average batch time: 0.417 secs\n",
      " Epoch:  6  Batch: 250 / 381  loss: 5.4987  Average batch time: 0.417 secs\n",
      " Epoch:  6  Batch: 300 / 381  loss: 5.4985  Average batch time: 0.419 secs\n",
      " Epoch:  6  Batch: 350 / 381  loss: 5.4986  Average batch time: 0.422 secs\n",
      "\n",
      "Training loss: 5.498761\n",
      "Time elapsed: 17.4 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4992\n",
      "Epoch 7\n",
      " Epoch:  7  Batch:  50 / 381  loss: 5.4982  Average batch time: 0.418 secs\n",
      " Epoch:  7  Batch: 100 / 381  loss: 5.4988  Average batch time: 0.401 secs\n",
      " Epoch:  7  Batch: 150 / 381  loss: 5.4986  Average batch time: 0.405 secs\n",
      " Epoch:  7  Batch: 200 / 381  loss: 5.4984  Average batch time: 0.413 secs\n",
      " Epoch:  7  Batch: 250 / 381  loss: 5.4984  Average batch time: 0.416 secs\n",
      " Epoch:  7  Batch: 300 / 381  loss: 5.4987  Average batch time: 0.412 secs\n",
      " Epoch:  7  Batch: 350 / 381  loss: 5.4989  Average batch time: 0.411 secs\n",
      "\n",
      "Training loss: 5.498918\n",
      "Time elapsed: 20.1 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4990\n",
      "Epoch 8\n",
      " Epoch:  8  Batch:  50 / 381  loss: 5.4990  Average batch time: 0.415 secs\n",
      " Epoch:  8  Batch: 100 / 381  loss: 5.4980  Average batch time: 0.405 secs\n",
      " Epoch:  8  Batch: 150 / 381  loss: 5.4990  Average batch time: 0.414 secs\n",
      " Epoch:  8  Batch: 200 / 381  loss: 5.4991  Average batch time: 0.412 secs\n",
      " Epoch:  8  Batch: 250 / 381  loss: 5.4991  Average batch time: 0.411 secs\n",
      " Epoch:  8  Batch: 300 / 381  loss: 5.4993  Average batch time: 0.410 secs\n",
      " Epoch:  8  Batch: 350 / 381  loss: 5.4997  Average batch time: 0.409 secs\n",
      "\n",
      "Training loss: 5.499160\n",
      "Time elapsed: 22.7 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4990\n",
      "Epoch 9\n",
      " Epoch:  9  Batch:  50 / 381  loss: 5.4985  Average batch time: 0.391 secs\n",
      " Epoch:  9  Batch: 100 / 381  loss: 5.4990  Average batch time: 0.390 secs\n",
      " Epoch:  9  Batch: 150 / 381  loss: 5.4980  Average batch time: 0.401 secs\n",
      " Epoch:  9  Batch: 200 / 381  loss: 5.4981  Average batch time: 0.398 secs\n",
      " Epoch:  9  Batch: 250 / 381  loss: 5.4988  Average batch time: 0.400 secs\n",
      " Epoch:  9  Batch: 300 / 381  loss: 5.4987  Average batch time: 0.397 secs\n",
      " Epoch:  9  Batch: 350 / 381  loss: 5.4987  Average batch time: 0.401 secs\n",
      "\n",
      "Training loss: 5.498946\n",
      "Time elapsed: 25.3 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4989\n",
      "Epoch 10\n",
      " Epoch: 10  Batch:  50 / 381  loss: 5.4937  Average batch time: 0.428 secs\n",
      " Epoch: 10  Batch: 100 / 381  loss: 5.4947  Average batch time: 0.435 secs\n",
      " Epoch: 10  Batch: 150 / 381  loss: 5.4958  Average batch time: 0.437 secs\n",
      " Epoch: 10  Batch: 200 / 381  loss: 5.4965  Average batch time: 0.436 secs\n",
      " Epoch: 10  Batch: 250 / 381  loss: 5.4974  Average batch time: 0.431 secs\n",
      " Epoch: 10  Batch: 300 / 381  loss: 5.4978  Average batch time: 0.428 secs\n",
      " Epoch: 10  Batch: 350 / 381  loss: 5.4983  Average batch time: 0.430 secs\n",
      "\n",
      "Training loss: 5.498882\n",
      "Time elapsed: 28.1 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4989\n",
      "Finished Training. Total time: 28.11252815326055 minutes.\n",
      "Best validation loss: 5.499, achieved on epoch #3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('',\n",
       " [5.498456403026431,\n",
       "  5.4985432900155935,\n",
       "  5.499834810342063,\n",
       "  5.499004454124631,\n",
       "  5.498705723780033,\n",
       "  5.498761203345351,\n",
       "  5.498917624706358,\n",
       "  5.499160371114575,\n",
       "  5.49894626872746,\n",
       "  5.498881923245007],\n",
       " [5.499294737110967,\n",
       "  5.499552519425102,\n",
       "  5.4987426633420196,\n",
       "  5.49883334533028,\n",
       "  5.498866993448009,\n",
       "  5.499194684235946,\n",
       "  5.499015497124714,\n",
       "  5.499010500700577,\n",
       "  5.498891747516135,\n",
       "  5.498885984006136],\n",
       " [])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(model, train_loader, valid_loader, criterion, optimizer, scheduler=None, num_epochs=EPOCHS, save_freq=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f0dea12-e960-40fb-943a-b5704d5e5820",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a7f4c19-6765-4255-868a-8286ad4cb9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started\n",
      "    Mode          : cuda\n",
      "    Model type    : <class 'models.LSTM_BASELINE_Model'>\n",
      "Epoch 1\n",
      " Epoch:  1  Batch:  50 / 381  loss: 5.4953  Average batch time: 0.411 secs\n",
      " Epoch:  1  Batch: 100 / 381  loss: 5.4978  Average batch time: 0.418 secs\n",
      " Epoch:  1  Batch: 150 / 381  loss: 5.4976  Average batch time: 0.417 secs\n",
      " Epoch:  1  Batch: 200 / 381  loss: 5.4971  Average batch time: 0.420 secs\n",
      " Epoch:  1  Batch: 250 / 381  loss: 5.4981  Average batch time: 0.414 secs\n",
      " Epoch:  1  Batch: 300 / 381  loss: 5.4979  Average batch time: 0.410 secs\n",
      " Epoch:  1  Batch: 350 / 381  loss: 5.4979  Average batch time: 0.409 secs\n",
      "\n",
      "Training loss: 5.498477\n",
      "Time elapsed: 2.6 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4986\n",
      "Epoch 2\n",
      " Epoch:  2  Batch:  50 / 381  loss: 5.4997  Average batch time: 0.399 secs\n",
      " Epoch:  2  Batch: 100 / 381  loss: 5.4966  Average batch time: 0.418 secs\n",
      " Epoch:  2  Batch: 150 / 381  loss: 5.4981  Average batch time: 0.423 secs\n",
      " Epoch:  2  Batch: 200 / 381  loss: 5.4984  Average batch time: 0.431 secs\n",
      " Epoch:  2  Batch: 250 / 381  loss: 5.4989  Average batch time: 0.432 secs\n",
      " Epoch:  2  Batch: 300 / 381  loss: 5.4982  Average batch time: 0.425 secs\n",
      " Epoch:  2  Batch: 350 / 381  loss: 5.4979  Average batch time: 0.425 secs\n",
      "\n",
      "Training loss: 5.498279\n",
      "Time elapsed: 5.3 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4986\n",
      "Epoch 3\n",
      " Epoch:  3  Batch:  50 / 381  loss: 5.4965  Average batch time: 0.416 secs\n",
      " Epoch:  3  Batch: 100 / 381  loss: 5.4976  Average batch time: 0.417 secs\n",
      " Epoch:  3  Batch: 150 / 381  loss: 5.4982  Average batch time: 0.414 secs\n",
      " Epoch:  3  Batch: 200 / 381  loss: 5.4980  Average batch time: 0.410 secs\n",
      " Epoch:  3  Batch: 250 / 381  loss: 5.4981  Average batch time: 0.406 secs\n",
      " Epoch:  3  Batch: 300 / 381  loss: 5.4981  Average batch time: 0.403 secs\n",
      " Epoch:  3  Batch: 350 / 381  loss: 5.4981  Average batch time: 0.410 secs\n",
      "\n",
      "Training loss: 5.498603\n",
      "Time elapsed: 8.0 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4987\n",
      "Epoch 4\n",
      " Epoch:  4  Batch:  50 / 381  loss: 5.4989  Average batch time: 0.434 secs\n",
      " Epoch:  4  Batch: 100 / 381  loss: 5.4998  Average batch time: 0.427 secs\n",
      " Epoch:  4  Batch: 150 / 381  loss: 5.5000  Average batch time: 0.424 secs\n",
      " Epoch:  4  Batch: 200 / 381  loss: 5.4998  Average batch time: 0.415 secs\n",
      " Epoch:  4  Batch: 250 / 381  loss: 5.4996  Average batch time: 0.418 secs\n",
      " Epoch:  4  Batch: 300 / 381  loss: 5.4999  Average batch time: 0.417 secs\n",
      " Epoch:  4  Batch: 350 / 381  loss: 5.4994  Average batch time: 0.412 secs\n",
      "\n",
      "Training loss: 5.499214\n",
      "Time elapsed: 10.6 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4987\n",
      "Epoch 5\n",
      " Epoch:  5  Batch:  50 / 381  loss: 5.4983  Average batch time: 0.441 secs\n",
      " Epoch:  5  Batch: 100 / 381  loss: 5.4987  Average batch time: 0.428 secs\n",
      " Epoch:  5  Batch: 150 / 381  loss: 5.4974  Average batch time: 0.424 secs\n",
      " Epoch:  5  Batch: 200 / 381  loss: 5.4979  Average batch time: 0.422 secs\n",
      " Epoch:  5  Batch: 250 / 381  loss: 5.4988  Average batch time: 0.421 secs\n",
      " Epoch:  5  Batch: 300 / 381  loss: 5.4988  Average batch time: 0.420 secs\n",
      " Epoch:  5  Batch: 350 / 381  loss: 5.4992  Average batch time: 0.421 secs\n",
      "\n",
      "Training loss: 5.499398\n",
      "Time elapsed: 13.3 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4990\n",
      "Epoch 6\n",
      " Epoch:  6  Batch:  50 / 381  loss: 5.4947  Average batch time: 0.658 secs\n",
      " Epoch:  6  Batch: 100 / 381  loss: 5.4962  Average batch time: 0.619 secs\n",
      " Epoch:  6  Batch: 150 / 381  loss: 5.4969  Average batch time: 0.613 secs\n",
      " Epoch:  6  Batch: 200 / 381  loss: 5.4979  Average batch time: 0.606 secs\n",
      " Epoch:  6  Batch: 250 / 381  loss: 5.4983  Average batch time: 0.602 secs\n",
      " Epoch:  6  Batch: 300 / 381  loss: 5.4990  Average batch time: 0.600 secs\n",
      " Epoch:  6  Batch: 350 / 381  loss: 5.4989  Average batch time: 0.603 secs\n",
      "\n",
      "Training loss: 5.498792\n",
      "Time elapsed: 17.2 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4985\n",
      "Epoch 7\n",
      " Epoch:  7  Batch:  50 / 381  loss: 5.5021  Average batch time: 0.404 secs\n",
      " Epoch:  7  Batch: 100 / 381  loss: 5.5009  Average batch time: 0.404 secs\n",
      " Epoch:  7  Batch: 150 / 381  loss: 5.5002  Average batch time: 0.405 secs\n",
      " Epoch:  7  Batch: 200 / 381  loss: 5.4989  Average batch time: 0.407 secs\n",
      " Epoch:  7  Batch: 250 / 381  loss: 5.4981  Average batch time: 0.415 secs\n",
      " Epoch:  7  Batch: 300 / 381  loss: 5.4987  Average batch time: 0.414 secs\n",
      " Epoch:  7  Batch: 350 / 381  loss: 5.4989  Average batch time: 0.412 secs\n",
      "\n",
      "Training loss: 5.499018\n",
      "Time elapsed: 19.9 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4986\n",
      "Epoch 8\n",
      " Epoch:  8  Batch:  50 / 381  loss: 5.4955  Average batch time: 0.413 secs\n",
      " Epoch:  8  Batch: 100 / 381  loss: 5.4983  Average batch time: 0.423 secs\n",
      " Epoch:  8  Batch: 150 / 381  loss: 5.4983  Average batch time: 0.427 secs\n",
      " Epoch:  8  Batch: 200 / 381  loss: 5.4986  Average batch time: 0.431 secs\n",
      " Epoch:  8  Batch: 250 / 381  loss: 5.4990  Average batch time: 0.429 secs\n",
      " Epoch:  8  Batch: 300 / 381  loss: 5.4987  Average batch time: 0.424 secs\n",
      " Epoch:  8  Batch: 350 / 381  loss: 5.4989  Average batch time: 0.429 secs\n",
      "\n",
      "Training loss: 5.498721\n",
      "Time elapsed: 22.6 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4986\n",
      "Epoch 9\n",
      " Epoch:  9  Batch:  50 / 381  loss: 5.4962  Average batch time: 0.433 secs\n",
      " Epoch:  9  Batch: 100 / 381  loss: 5.4983  Average batch time: 0.426 secs\n",
      " Epoch:  9  Batch: 150 / 381  loss: 5.4986  Average batch time: 0.423 secs\n",
      " Epoch:  9  Batch: 200 / 381  loss: 5.4996  Average batch time: 0.420 secs\n",
      " Epoch:  9  Batch: 250 / 381  loss: 5.4989  Average batch time: 0.413 secs\n",
      " Epoch:  9  Batch: 300 / 381  loss: 5.4991  Average batch time: 0.410 secs\n",
      " Epoch:  9  Batch: 350 / 381  loss: 5.4986  Average batch time: 0.408 secs\n",
      "\n",
      "Training loss: 5.498702\n",
      "Time elapsed: 25.3 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4987\n",
      "Epoch 10\n",
      " Epoch: 10  Batch:  50 / 381  loss: 5.5002  Average batch time: 0.420 secs\n",
      " Epoch: 10  Batch: 100 / 381  loss: 5.4983  Average batch time: 0.416 secs\n",
      " Epoch: 10  Batch: 150 / 381  loss: 5.4987  Average batch time: 0.420 secs\n",
      " Epoch: 10  Batch: 200 / 381  loss: 5.4976  Average batch time: 0.417 secs\n",
      " Epoch: 10  Batch: 250 / 381  loss: 5.4978  Average batch time: 0.426 secs\n",
      " Epoch: 10  Batch: 300 / 381  loss: 5.4980  Average batch time: 0.432 secs\n",
      " Epoch: 10  Batch: 350 / 381  loss: 5.4983  Average batch time: 0.426 secs\n",
      "\n",
      "Training loss: 5.499545\n",
      "Time elapsed: 28.0 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4988\n",
      "Epoch 11\n",
      " Epoch: 11  Batch:  50 / 381  loss: 5.5010  Average batch time: 0.437 secs\n",
      " Epoch: 11  Batch: 100 / 381  loss: 5.4972  Average batch time: 0.449 secs\n",
      " Epoch: 11  Batch: 150 / 381  loss: 5.4978  Average batch time: 0.433 secs\n",
      " Epoch: 11  Batch: 200 / 381  loss: 5.4981  Average batch time: 0.426 secs\n",
      " Epoch: 11  Batch: 250 / 381  loss: 5.4989  Average batch time: 0.426 secs\n",
      " Epoch: 11  Batch: 300 / 381  loss: 5.4995  Average batch time: 0.424 secs\n",
      " Epoch: 11  Batch: 350 / 381  loss: 5.4996  Average batch time: 0.426 secs\n",
      "\n",
      "Training loss: 5.499411\n",
      "Time elapsed: 30.8 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4988\n",
      "Epoch 12\n",
      " Epoch: 12  Batch:  50 / 381  loss: 5.4994  Average batch time: 0.451 secs\n",
      " Epoch: 12  Batch: 100 / 381  loss: 5.4980  Average batch time: 0.428 secs\n",
      " Epoch: 12  Batch: 150 / 381  loss: 5.4976  Average batch time: 0.425 secs\n",
      " Epoch: 12  Batch: 200 / 381  loss: 5.4973  Average batch time: 0.425 secs\n",
      " Epoch: 12  Batch: 250 / 381  loss: 5.4983  Average batch time: 0.434 secs\n",
      " Epoch: 12  Batch: 300 / 381  loss: 5.4985  Average batch time: 0.434 secs\n",
      " Epoch: 12  Batch: 350 / 381  loss: 5.4982  Average batch time: 0.440 secs\n",
      "\n",
      "Training loss: 5.498502\n",
      "Time elapsed: 33.7 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4988\n",
      "Epoch 13\n",
      " Epoch: 13  Batch:  50 / 381  loss: 5.4964  Average batch time: 0.460 secs\n",
      " Epoch: 13  Batch: 100 / 381  loss: 5.4971  Average batch time: 0.455 secs\n",
      " Epoch: 13  Batch: 150 / 381  loss: 5.4973  Average batch time: 0.446 secs\n",
      " Epoch: 13  Batch: 200 / 381  loss: 5.4979  Average batch time: 0.444 secs\n",
      " Epoch: 13  Batch: 250 / 381  loss: 5.4970  Average batch time: 0.437 secs\n",
      " Epoch: 13  Batch: 300 / 381  loss: 5.4974  Average batch time: 0.431 secs\n",
      " Epoch: 13  Batch: 350 / 381  loss: 5.4983  Average batch time: 0.428 secs\n",
      "\n",
      "Training loss: 5.498588\n",
      "Time elapsed: 36.4 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4987\n",
      "Epoch 14\n",
      " Epoch: 14  Batch:  50 / 381  loss: 5.5021  Average batch time: 0.418 secs\n",
      " Epoch: 14  Batch: 100 / 381  loss: 5.4982  Average batch time: 0.416 secs\n",
      " Epoch: 14  Batch: 150 / 381  loss: 5.4974  Average batch time: 0.408 secs\n",
      " Epoch: 14  Batch: 200 / 381  loss: 5.4974  Average batch time: 0.418 secs\n",
      " Epoch: 14  Batch: 250 / 381  loss: 5.4979  Average batch time: 0.419 secs\n",
      " Epoch: 14  Batch: 300 / 381  loss: 5.4985  Average batch time: 0.424 secs\n",
      " Epoch: 14  Batch: 350 / 381  loss: 5.4988  Average batch time: 0.421 secs\n",
      "\n",
      "Training loss: 5.499056\n",
      "Time elapsed: 39.2 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4985\n",
      "Epoch 15\n",
      " Epoch: 15  Batch:  50 / 381  loss: 5.4987  Average batch time: 0.424 secs\n",
      " Epoch: 15  Batch: 100 / 381  loss: 5.4980  Average batch time: 0.428 secs\n",
      " Epoch: 15  Batch: 150 / 381  loss: 5.4985  Average batch time: 0.414 secs\n",
      " Epoch: 15  Batch: 200 / 381  loss: 5.4990  Average batch time: 0.419 secs\n",
      " Epoch: 15  Batch: 250 / 381  loss: 5.4991  Average batch time: 0.411 secs\n",
      " Epoch: 15  Batch: 300 / 381  loss: 5.4982  Average batch time: 0.411 secs\n",
      " Epoch: 15  Batch: 350 / 381  loss: 5.4985  Average batch time: 0.408 secs\n",
      "\n",
      "Training loss: 5.498524\n",
      "Time elapsed: 41.9 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4984\n",
      "Epoch 16\n",
      " Epoch: 16  Batch:  50 / 381  loss: 5.5009  Average batch time: 0.479 secs\n",
      " Epoch: 16  Batch: 100 / 381  loss: 5.4975  Average batch time: 0.447 secs\n",
      " Epoch: 16  Batch: 150 / 381  loss: 5.4969  Average batch time: 0.454 secs\n",
      " Epoch: 16  Batch: 200 / 381  loss: 5.4980  Average batch time: 0.441 secs\n",
      " Epoch: 16  Batch: 250 / 381  loss: 5.4983  Average batch time: 0.429 secs\n",
      " Epoch: 16  Batch: 300 / 381  loss: 5.4990  Average batch time: 0.425 secs\n",
      " Epoch: 16  Batch: 350 / 381  loss: 5.4987  Average batch time: 0.420 secs\n",
      "\n",
      "Training loss: 5.498778\n",
      "Time elapsed: 44.6 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4985\n",
      "Epoch 17\n",
      " Epoch: 17  Batch:  50 / 381  loss: 5.4952  Average batch time: 0.441 secs\n",
      " Epoch: 17  Batch: 100 / 381  loss: 5.4945  Average batch time: 0.421 secs\n",
      " Epoch: 17  Batch: 150 / 381  loss: 5.4972  Average batch time: 0.413 secs\n",
      " Epoch: 17  Batch: 200 / 381  loss: 5.4970  Average batch time: 0.422 secs\n",
      " Epoch: 17  Batch: 250 / 381  loss: 5.4974  Average batch time: 0.420 secs\n",
      " Epoch: 17  Batch: 300 / 381  loss: 5.4978  Average batch time: 0.422 secs\n",
      " Epoch: 17  Batch: 350 / 381  loss: 5.4983  Average batch time: 0.421 secs\n",
      "\n",
      "Training loss: 5.498442\n",
      "Time elapsed: 47.3 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4986\n",
      "Epoch 18\n",
      " Epoch: 18  Batch:  50 / 381  loss: 5.4977  Average batch time: 0.426 secs\n",
      " Epoch: 18  Batch: 100 / 381  loss: 5.5000  Average batch time: 0.429 secs\n",
      " Epoch: 18  Batch: 150 / 381  loss: 5.5004  Average batch time: 0.430 secs\n",
      " Epoch: 18  Batch: 200 / 381  loss: 5.4994  Average batch time: 0.422 secs\n",
      " Epoch: 18  Batch: 250 / 381  loss: 5.4997  Average batch time: 0.424 secs\n",
      " Epoch: 18  Batch: 300 / 381  loss: 5.4992  Average batch time: 0.422 secs\n",
      " Epoch: 18  Batch: 350 / 381  loss: 5.4990  Average batch time: 0.424 secs\n",
      "\n",
      "Training loss: 5.498613\n",
      "Time elapsed: 50.1 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4987\n",
      "Epoch 19\n",
      " Epoch: 19  Batch:  50 / 381  loss: 5.4999  Average batch time: 0.394 secs\n",
      " Epoch: 19  Batch: 100 / 381  loss: 5.5022  Average batch time: 0.397 secs\n",
      " Epoch: 19  Batch: 150 / 381  loss: 5.5008  Average batch time: 0.395 secs\n",
      " Epoch: 19  Batch: 200 / 381  loss: 5.5003  Average batch time: 0.401 secs\n",
      " Epoch: 19  Batch: 250 / 381  loss: 5.4994  Average batch time: 0.408 secs\n",
      " Epoch: 19  Batch: 300 / 381  loss: 5.4998  Average batch time: 0.409 secs\n",
      " Epoch: 19  Batch: 350 / 381  loss: 5.4992  Average batch time: 0.412 secs\n",
      " Epoch: 20  Batch: 250 / 381  loss: 5.4980  Average batch time: 0.418 secs\n",
      " Epoch: 20  Batch: 300 / 381  loss: 5.4984  Average batch time: 0.421 secs\n",
      " Epoch: 20  Batch: 350 / 381  loss: 5.4989  Average batch time: 0.420 secs\n",
      "\n",
      "Training loss: 5.498999\n",
      "Time elapsed: 55.5 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4983\n",
      "Epoch 21\n",
      " Epoch: 21  Batch:  50 / 381  loss: 5.4997  Average batch time: 0.401 secs\n",
      " Epoch: 21  Batch: 100 / 381  loss: 5.4988  Average batch time: 0.409 secs\n",
      " Epoch: 21  Batch: 150 / 381  loss: 5.4991  Average batch time: 0.421 secs\n",
      " Epoch: 21  Batch: 200 / 381  loss: 5.4987  Average batch time: 0.415 secs\n",
      " Epoch: 21  Batch: 250 / 381  loss: 5.4984  Average batch time: 0.421 secs\n",
      " Epoch: 21  Batch: 300 / 381  loss: 5.4988  Average batch time: 0.428 secs\n",
      " Epoch: 21  Batch: 350 / 381  loss: 5.4987  Average batch time: 0.426 secs\n",
      "\n",
      "Training loss: 5.498511\n",
      "Time elapsed: 58.3 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4985\n",
      "Epoch 22\n",
      " Epoch: 22  Batch:  50 / 381  loss: 5.4959  Average batch time: 0.403 secs\n",
      " Epoch: 22  Batch: 100 / 381  loss: 5.4985  Average batch time: 0.408 secs\n",
      " Epoch: 22  Batch: 150 / 381  loss: 5.4980  Average batch time: 0.416 secs\n",
      " Epoch: 22  Batch: 200 / 381  loss: 5.4986  Average batch time: 0.414 secs\n",
      " Epoch: 22  Batch: 250 / 381  loss: 5.4986  Average batch time: 0.416 secs\n",
      " Epoch: 22  Batch: 300 / 381  loss: 5.4984  Average batch time: 0.418 secs\n",
      " Epoch: 22  Batch: 350 / 381  loss: 5.4991  Average batch time: 0.415 secs\n",
      "\n",
      "Training loss: 5.499041\n",
      "Time elapsed: 60.9 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4983\n",
      "Epoch 23\n",
      " Epoch: 23  Batch:  50 / 381  loss: 5.4979  Average batch time: 0.441 secs\n",
      " Epoch: 23  Batch: 100 / 381  loss: 5.4979  Average batch time: 0.442 secs\n",
      " Epoch: 23  Batch: 150 / 381  loss: 5.4975  Average batch time: 0.482 secs\n",
      " Epoch: 23  Batch: 200 / 381  loss: 5.4976  Average batch time: 0.535 secs\n",
      " Epoch: 23  Batch: 250 / 381  loss: 5.4976  Average batch time: 0.563 secs\n",
      " Epoch: 23  Batch: 300 / 381  loss: 5.4983  Average batch time: 0.586 secs\n",
      " Epoch: 23  Batch: 350 / 381  loss: 5.4984  Average batch time: 0.604 secs\n",
      "\n",
      "Training loss: 5.498682\n",
      "Time elapsed: 64.9 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4989\n",
      "Epoch 24\n",
      " Epoch: 24  Batch:  50 / 381  loss: 5.4989  Average batch time: 0.428 secs\n",
      " Epoch: 24  Batch: 100 / 381  loss: 5.5001  Average batch time: 0.424 secs\n",
      " Epoch: 24  Batch: 150 / 381  loss: 5.4985  Average batch time: 0.424 secs\n",
      " Epoch: 24  Batch: 200 / 381  loss: 5.4980  Average batch time: 0.421 secs\n",
      " Epoch: 24  Batch: 250 / 381  loss: 5.4976  Average batch time: 0.419 secs\n",
      " Epoch: 24  Batch: 300 / 381  loss: 5.4985  Average batch time: 0.416 secs\n",
      " Epoch: 24  Batch: 350 / 381  loss: 5.4988  Average batch time: 0.416 secs\n",
      "\n",
      "Training loss: 5.498393\n",
      "Time elapsed: 67.6 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4987\n",
      "Epoch 25\n",
      " Epoch: 25  Batch:  50 / 381  loss: 5.4962  Average batch time: 0.418 secs\n",
      " Epoch: 25  Batch: 100 / 381  loss: 5.4980  Average batch time: 0.426 secs\n",
      " Epoch: 25  Batch: 150 / 381  loss: 5.4988  Average batch time: 0.421 secs\n",
      " Epoch: 25  Batch: 200 / 381  loss: 5.4984  Average batch time: 0.419 secs\n",
      " Epoch: 25  Batch: 250 / 381  loss: 5.4985  Average batch time: 0.418 secs\n",
      " Epoch: 25  Batch: 300 / 381  loss: 5.4987  Average batch time: 0.417 secs\n",
      " Epoch: 25  Batch: 350 / 381  loss: 5.4986  Average batch time: 0.420 secs\n",
      "\n",
      "Training loss: 5.498703\n",
      "Time elapsed: 70.3 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4983\n",
      "Epoch 26\n",
      " Epoch: 26  Batch:  50 / 381  loss: 5.5009  Average batch time: 0.394 secs\n",
      " Epoch: 26  Batch: 100 / 381  loss: 5.5020  Average batch time: 0.389 secs\n",
      " Epoch: 26  Batch: 150 / 381  loss: 5.5014  Average batch time: 0.400 secs\n",
      " Epoch: 26  Batch: 200 / 381  loss: 5.5009  Average batch time: 0.397 secs\n",
      " Epoch: 26  Batch: 250 / 381  loss: 5.5011  Average batch time: 0.395 secs\n",
      " Epoch: 26  Batch: 300 / 381  loss: 5.5006  Average batch time: 0.396 secs\n",
      " Epoch: 26  Batch: 350 / 381  loss: 5.4995  Average batch time: 0.397 secs\n",
      "\n",
      "Training loss: 5.499116\n",
      "Time elapsed: 72.8 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4981\n",
      "Epoch 27\n",
      " Epoch: 27  Batch:  50 / 381  loss: 5.4993  Average batch time: 0.438 secs\n",
      " Epoch: 27  Batch: 100 / 381  loss: 5.4995  Average batch time: 0.425 secs\n",
      " Epoch: 27  Batch: 150 / 381  loss: 5.5000  Average batch time: 0.426 secs\n",
      " Epoch: 27  Batch: 200 / 381  loss: 5.4989  Average batch time: 0.422 secs\n",
      " Epoch: 27  Batch: 250 / 381  loss: 5.4986  Average batch time: 0.419 secs\n",
      " Epoch: 27  Batch: 300 / 381  loss: 5.4984  Average batch time: 0.417 secs\n",
      " Epoch: 27  Batch: 350 / 381  loss: 5.4986  Average batch time: 0.413 secs\n",
      "\n",
      "Training loss: 5.498558\n",
      "Time elapsed: 75.5 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4985\n",
      "Epoch 28\n",
      " Epoch: 28  Batch:  50 / 381  loss: 5.4986  Average batch time: 0.397 secs\n",
      " Epoch: 28  Batch: 100 / 381  loss: 5.4987  Average batch time: 0.400 secs\n",
      " Epoch: 28  Batch: 150 / 381  loss: 5.4989  Average batch time: 0.398 secs\n",
      " Epoch: 28  Batch: 200 / 381  loss: 5.4995  Average batch time: 0.404 secs\n",
      " Epoch: 28  Batch: 250 / 381  loss: 5.4999  Average batch time: 0.408 secs\n",
      " Epoch: 28  Batch: 300 / 381  loss: 5.4992  Average batch time: 0.409 secs\n",
      " Epoch: 28  Batch: 350 / 381  loss: 5.4986  Average batch time: 0.409 secs\n",
      "\n",
      "Training loss: 5.498866\n",
      "Time elapsed: 78.1 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4979\n",
      "Epoch 29\n",
      " Epoch: 29  Batch:  50 / 381  loss: 5.4955  Average batch time: 0.406 secs\n",
      " Epoch: 29  Batch: 100 / 381  loss: 5.4977  Average batch time: 0.398 secs\n",
      " Epoch: 29  Batch: 150 / 381  loss: 5.4976  Average batch time: 0.405 secs\n",
      " Epoch: 29  Batch: 200 / 381  loss: 5.4982  Average batch time: 0.406 secs\n",
      " Epoch: 29  Batch: 250 / 381  loss: 5.4986  Average batch time: 0.413 secs\n",
      " Epoch: 29  Batch: 300 / 381  loss: 5.4984  Average batch time: 0.416 secs\n",
      " Epoch: 29  Batch: 350 / 381  loss: 5.4984  Average batch time: 0.417 secs\n",
      "\n",
      "Training loss: 5.498521\n",
      "Time elapsed: 80.8 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4974\n",
      "Epoch 30\n",
      " Epoch: 30  Batch:  50 / 381  loss: 5.4976  Average batch time: 0.416 secs\n",
      " Epoch: 30  Batch: 100 / 381  loss: 5.4979  Average batch time: 0.417 secs\n",
      " Epoch: 30  Batch: 150 / 381  loss: 5.4968  Average batch time: 0.433 secs\n",
      " Epoch: 30  Batch: 200 / 381  loss: 5.4970  Average batch time: 0.427 secs\n",
      " Epoch: 30  Batch: 250 / 381  loss: 5.4976  Average batch time: 0.420 secs\n",
      " Epoch: 30  Batch: 300 / 381  loss: 5.4979  Average batch time: 0.424 secs\n",
      " Epoch: 30  Batch: 350 / 381  loss: 5.4984  Average batch time: 0.429 secs\n",
      "\n",
      "Training loss: 5.498425\n",
      "Time elapsed: 83.6 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4980\n",
      "Epoch 31\n",
      " Epoch: 31  Batch:  50 / 381  loss: 5.5001  Average batch time: 0.405 secs\n",
      " Epoch: 31  Batch: 100 / 381  loss: 5.4990  Average batch time: 0.402 secs\n",
      " Epoch: 31  Batch: 150 / 381  loss: 5.5002  Average batch time: 0.421 secs\n",
      " Epoch: 31  Batch: 200 / 381  loss: 5.4987  Average batch time: 0.421 secs\n",
      " Epoch: 31  Batch: 250 / 381  loss: 5.4987  Average batch time: 0.418 secs\n",
      " Epoch: 31  Batch: 300 / 381  loss: 5.4989  Average batch time: 0.417 secs\n",
      " Epoch: 31  Batch: 350 / 381  loss: 5.4989  Average batch time: 0.414 secs\n",
      "\n",
      "Training loss: 5.499184\n",
      "Time elapsed: 86.3 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4979\n",
      "Epoch 32\n",
      " Epoch: 32  Batch:  50 / 381  loss: 5.5008  Average batch time: 0.449 secs\n",
      " Epoch: 32  Batch: 100 / 381  loss: 5.4987  Average batch time: 0.442 secs\n",
      " Epoch: 32  Batch: 150 / 381  loss: 5.4987  Average batch time: 0.432 secs\n",
      " Epoch: 32  Batch: 200 / 381  loss: 5.4994  Average batch time: 0.429 secs\n",
      " Epoch: 32  Batch: 250 / 381  loss: 5.4990  Average batch time: 0.424 secs\n",
      " Epoch: 32  Batch: 300 / 381  loss: 5.4996  Average batch time: 0.425 secs\n",
      " Epoch: 32  Batch: 350 / 381  loss: 5.4993  Average batch time: 0.425 secs\n",
      "\n",
      "Training loss: 5.498911\n",
      "Time elapsed: 89.0 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4978\n",
      "Epoch 33\n",
      " Epoch: 33  Batch:  50 / 381  loss: 5.4986  Average batch time: 0.419 secs\n",
      " Epoch: 33  Batch: 100 / 381  loss: 5.4980  Average batch time: 0.410 secs\n",
      " Epoch: 33  Batch: 150 / 381  loss: 5.5003  Average batch time: 0.413 secs\n",
      " Epoch: 33  Batch: 200 / 381  loss: 5.5000  Average batch time: 0.418 secs\n",
      " Epoch: 33  Batch: 250 / 381  loss: 5.4998  Average batch time: 0.411 secs\n",
      " Epoch: 33  Batch: 300 / 381  loss: 5.4986  Average batch time: 0.412 secs\n",
      " Epoch: 33  Batch: 350 / 381  loss: 5.4986  Average batch time: 0.410 secs\n",
      "\n",
      "Training loss: 5.498574\n",
      "Time elapsed: 91.7 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4984\n",
      "Epoch 34\n",
      " Epoch: 34  Batch:  50 / 381  loss: 5.4959  Average batch time: 0.439 secs\n",
      " Epoch: 34  Batch: 100 / 381  loss: 5.4956  Average batch time: 0.453 secs\n",
      " Epoch: 34  Batch: 150 / 381  loss: 5.4965  Average batch time: 0.431 secs\n",
      " Epoch: 34  Batch: 200 / 381  loss: 5.4971  Average batch time: 0.423 secs\n",
      " Epoch: 34  Batch: 250 / 381  loss: 5.4980  Average batch time: 0.418 secs\n",
      " Epoch: 34  Batch: 300 / 381  loss: 5.4978  Average batch time: 0.421 secs\n",
      " Epoch: 34  Batch: 350 / 381  loss: 5.4978  Average batch time: 0.421 secs\n",
      "\n",
      "Training loss: 5.498400\n",
      "Time elapsed: 94.4 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4979\n",
      "Epoch 35\n",
      " Epoch: 35  Batch:  50 / 381  loss: 5.4954  Average batch time: 0.404 secs\n",
      " Epoch: 35  Batch: 100 / 381  loss: 5.4972  Average batch time: 0.418 secs\n",
      " Epoch: 35  Batch: 150 / 381  loss: 5.4983  Average batch time: 0.426 secs\n",
      " Epoch: 35  Batch: 200 / 381  loss: 5.4984  Average batch time: 0.421 secs\n",
      " Epoch: 35  Batch: 250 / 381  loss: 5.4982  Average batch time: 0.419 secs\n",
      " Epoch: 35  Batch: 300 / 381  loss: 5.4980  Average batch time: 0.423 secs\n",
      " Epoch: 35  Batch: 350 / 381  loss: 5.4983  Average batch time: 0.424 secs\n",
      "\n",
      "Training loss: 5.498049\n",
      "Time elapsed: 97.2 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4977\n",
      "Epoch 36\n",
      " Epoch: 36  Batch:  50 / 381  loss: 5.4961  Average batch time: 0.398 secs\n",
      " Epoch: 36  Batch: 100 / 381  loss: 5.4971  Average batch time: 0.404 secs\n",
      " Epoch: 36  Batch: 150 / 381  loss: 5.4976  Average batch time: 0.407 secs\n",
      " Epoch: 36  Batch: 200 / 381  loss: 5.4985  Average batch time: 0.422 secs\n",
      " Epoch: 36  Batch: 250 / 381  loss: 5.4987  Average batch time: 0.426 secs\n",
      " Epoch: 36  Batch: 300 / 381  loss: 5.4986  Average batch time: 0.431 secs\n",
      " Epoch: 36  Batch: 350 / 381  loss: 5.4989  Average batch time: 0.428 secs\n",
      "\n",
      "Training loss: 5.498845\n",
      "Time elapsed: 100.0 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4977\n",
      "Epoch 37\n",
      " Epoch: 37  Batch:  50 / 381  loss: 5.4938  Average batch time: 0.400 secs\n",
      " Epoch: 37  Batch: 100 / 381  loss: 5.4946  Average batch time: 0.422 secs\n",
      " Epoch: 37  Batch: 150 / 381  loss: 5.4951  Average batch time: 0.420 secs\n",
      " Epoch: 37  Batch: 200 / 381  loss: 5.4964  Average batch time: 0.416 secs\n",
      " Epoch: 37  Batch: 250 / 381  loss: 5.4964  Average batch time: 0.416 secs\n",
      " Epoch: 37  Batch: 300 / 381  loss: 5.4969  Average batch time: 0.411 secs\n",
      " Epoch: 37  Batch: 350 / 381  loss: 5.4978  Average batch time: 0.414 secs\n",
      "\n",
      "Training loss: 5.498346\n",
      "Time elapsed: 102.7 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4981\n",
      "Epoch 38\n",
      " Epoch: 38  Batch:  50 / 381  loss: 5.4961  Average batch time: 0.446 secs\n",
      " Epoch: 38  Batch: 100 / 381  loss: 5.4973  Average batch time: 0.422 secs\n",
      " Epoch: 38  Batch: 150 / 381  loss: 5.4987  Average batch time: 0.417 secs\n",
      " Epoch: 38  Batch: 200 / 381  loss: 5.4983  Average batch time: 0.423 secs\n",
      " Epoch: 38  Batch: 250 / 381  loss: 5.4989  Average batch time: 0.417 secs\n",
      " Epoch: 38  Batch: 300 / 381  loss: 5.4989  Average batch time: 0.415 secs\n",
      " Epoch: 38  Batch: 350 / 381  loss: 5.4984  Average batch time: 0.416 secs\n",
      "\n",
      "Training loss: 5.498570\n",
      "Time elapsed: 105.4 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4984\n",
      "Epoch 39\n",
      " Epoch: 39  Batch:  50 / 381  loss: 5.4980  Average batch time: 0.414 secs\n",
      " Epoch: 39  Batch: 100 / 381  loss: 5.4973  Average batch time: 0.432 secs\n",
      " Epoch: 39  Batch: 150 / 381  loss: 5.4980  Average batch time: 0.440 secs\n",
      " Epoch: 39  Batch: 200 / 381  loss: 5.4974  Average batch time: 0.436 secs\n",
      " Epoch: 39  Batch: 250 / 381  loss: 5.4983  Average batch time: 0.433 secs\n",
      " Epoch: 39  Batch: 300 / 381  loss: 5.4982  Average batch time: 0.430 secs\n",
      " Epoch: 39  Batch: 350 / 381  loss: 5.4991  Average batch time: 0.431 secs\n",
      "\n",
      "Training loss: 5.499395\n",
      "Time elapsed: 108.2 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4986\n",
      "Epoch 40\n",
      " Epoch: 40  Batch:  50 / 381  loss: 5.5027  Average batch time: 0.425 secs\n",
      " Epoch: 40  Batch: 100 / 381  loss: 5.4999  Average batch time: 0.431 secs\n",
      " Epoch: 40  Batch: 150 / 381  loss: 5.5009  Average batch time: 0.420 secs\n",
      " Epoch: 40  Batch: 200 / 381  loss: 5.5001  Average batch time: 0.415 secs\n",
      " Epoch: 40  Batch: 250 / 381  loss: 5.5000  Average batch time: 0.416 secs\n",
      " Epoch: 40  Batch: 300 / 381  loss: 5.4996  Average batch time: 0.415 secs\n",
      " Epoch: 40  Batch: 350 / 381  loss: 5.4987  Average batch time: 0.415 secs\n",
      "\n",
      "Training loss: 5.498776\n",
      "Time elapsed: 110.9 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4983\n",
      "Epoch 41\n",
      " Epoch: 41  Batch:  50 / 381  loss: 5.5026  Average batch time: 0.424 secs\n",
      " Epoch: 41  Batch: 100 / 381  loss: 5.5008  Average batch time: 0.503 secs\n",
      " Epoch: 41  Batch: 150 / 381  loss: 5.4990  Average batch time: 0.584 secs\n",
      " Epoch: 41  Batch: 200 / 381  loss: 5.4998  Average batch time: 0.614 secs\n",
      " Epoch: 41  Batch: 250 / 381  loss: 5.4994  Average batch time: 0.625 secs\n",
      " Epoch: 41  Batch: 300 / 381  loss: 5.4990  Average batch time: 0.628 secs\n",
      " Epoch: 41  Batch: 350 / 381  loss: 5.4985  Average batch time: 0.634 secs\n",
      "\n",
      "Training loss: 5.498720\n",
      "Time elapsed: 115.0 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4981\n",
      "Epoch 42\n",
      " Epoch: 42  Batch:  50 / 381  loss: 5.4955  Average batch time: 0.388 secs\n",
      " Epoch: 42  Batch: 100 / 381  loss: 5.4983  Average batch time: 0.415 secs\n",
      " Epoch: 42  Batch: 150 / 381  loss: 5.4980  Average batch time: 0.412 secs\n",
      " Epoch: 42  Batch: 200 / 381  loss: 5.4977  Average batch time: 0.411 secs\n",
      " Epoch: 42  Batch: 250 / 381  loss: 5.4978  Average batch time: 0.417 secs\n",
      " Epoch: 42  Batch: 300 / 381  loss: 5.4975  Average batch time: 0.422 secs\n",
      " Epoch: 42  Batch: 350 / 381  loss: 5.4979  Average batch time: 0.423 secs\n",
      "\n",
      "Training loss: 5.498613\n",
      "Time elapsed: 117.7 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4979\n",
      "Epoch 43\n",
      " Epoch: 43  Batch:  50 / 381  loss: 5.4994  Average batch time: 0.456 secs\n",
      " Epoch: 43  Batch: 100 / 381  loss: 5.4996  Average batch time: 0.429 secs\n",
      " Epoch: 43  Batch: 150 / 381  loss: 5.4979  Average batch time: 0.420 secs\n",
      " Epoch: 43  Batch: 200 / 381  loss: 5.4991  Average batch time: 0.427 secs\n",
      " Epoch: 43  Batch: 250 / 381  loss: 5.4991  Average batch time: 0.426 secs\n",
      " Epoch: 43  Batch: 300 / 381  loss: 5.4985  Average batch time: 0.428 secs\n",
      " Epoch: 43  Batch: 350 / 381  loss: 5.4987  Average batch time: 0.429 secs\n",
      "\n",
      "Training loss: 5.498210\n",
      "Time elapsed: 120.5 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4980\n",
      "Epoch 44\n",
      " Epoch: 44  Batch:  50 / 381  loss: 5.5021  Average batch time: 0.402 secs\n",
      " Epoch: 44  Batch: 100 / 381  loss: 5.5005  Average batch time: 0.423 secs\n",
      " Epoch: 44  Batch: 150 / 381  loss: 5.4983  Average batch time: 0.436 secs\n",
      " Epoch: 44  Batch: 200 / 381  loss: 5.4981  Average batch time: 0.437 secs\n",
      " Epoch: 44  Batch: 250 / 381  loss: 5.4976  Average batch time: 0.429 secs\n",
      " Epoch: 44  Batch: 300 / 381  loss: 5.4974  Average batch time: 0.426 secs\n",
      " Epoch: 44  Batch: 350 / 381  loss: 5.4978  Average batch time: 0.428 secs\n",
      "\n",
      "Training loss: 5.498352\n",
      "Time elapsed: 123.2 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4976\n",
      "Epoch 45\n",
      " Epoch: 45  Batch:  50 / 381  loss: 5.5008  Average batch time: 0.447 secs\n",
      " Epoch: 45  Batch: 100 / 381  loss: 5.5009  Average batch time: 0.436 secs\n",
      " Epoch: 45  Batch: 150 / 381  loss: 5.4987  Average batch time: 0.437 secs\n",
      " Epoch: 45  Batch: 200 / 381  loss: 5.4984  Average batch time: 0.447 secs\n",
      " Epoch: 45  Batch: 250 / 381  loss: 5.4979  Average batch time: 0.445 secs\n",
      " Epoch: 45  Batch: 300 / 381  loss: 5.4982  Average batch time: 0.445 secs\n",
      " Epoch: 45  Batch: 350 / 381  loss: 5.4978  Average batch time: 0.444 secs\n",
      "\n",
      "Training loss: 5.498887\n",
      "Time elapsed: 126.1 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4978\n",
      "Epoch 46\n",
      " Epoch: 46  Batch:  50 / 381  loss: 5.4996  Average batch time: 0.417 secs\n",
      " Epoch: 46  Batch: 100 / 381  loss: 5.4986  Average batch time: 0.432 secs\n",
      " Epoch: 46  Batch: 150 / 381  loss: 5.4973  Average batch time: 0.437 secs\n",
      " Epoch: 46  Batch: 200 / 381  loss: 5.4984  Average batch time: 0.439 secs\n",
      " Epoch: 46  Batch: 250 / 381  loss: 5.4977  Average batch time: 0.437 secs\n",
      " Epoch: 46  Batch: 300 / 381  loss: 5.4979  Average batch time: 0.432 secs\n",
      " Epoch: 46  Batch: 350 / 381  loss: 5.4981  Average batch time: 0.433 secs\n",
      "\n",
      "Training loss: 5.498023\n",
      "Time elapsed: 128.9 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4977\n",
      "Epoch 47\n",
      " Epoch: 47  Batch:  50 / 381  loss: 5.4987  Average batch time: 0.462 secs\n",
      " Epoch: 47  Batch: 100 / 381  loss: 5.4975  Average batch time: 0.446 secs\n",
      " Epoch: 47  Batch: 150 / 381  loss: 5.4986  Average batch time: 0.445 secs\n",
      " Epoch: 47  Batch: 200 / 381  loss: 5.4989  Average batch time: 0.442 secs\n",
      " Epoch: 47  Batch: 250 / 381  loss: 5.4986  Average batch time: 0.438 secs\n",
      " Epoch: 47  Batch: 300 / 381  loss: 5.4986  Average batch time: 0.435 secs\n",
      " Epoch: 47  Batch: 350 / 381  loss: 5.4984  Average batch time: 0.438 secs\n",
      "\n",
      "Training loss: 5.498608\n",
      "Time elapsed: 131.8 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4976\n",
      "Epoch 48\n",
      " Epoch: 48  Batch:  50 / 381  loss: 5.4964  Average batch time: 0.424 secs\n",
      " Epoch: 48  Batch: 100 / 381  loss: 5.4971  Average batch time: 0.418 secs\n",
      " Epoch: 48  Batch: 150 / 381  loss: 5.4983  Average batch time: 0.410 secs\n",
      " Epoch: 48  Batch: 200 / 381  loss: 5.4982  Average batch time: 0.411 secs\n",
      " Epoch: 48  Batch: 250 / 381  loss: 5.4977  Average batch time: 0.417 secs\n",
      " Epoch: 48  Batch: 300 / 381  loss: 5.4983  Average batch time: 0.416 secs\n",
      " Epoch: 48  Batch: 350 / 381  loss: 5.4984  Average batch time: 0.414 secs\n",
      "\n",
      "Training loss: 5.498053\n",
      "Time elapsed: 134.5 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4977\n",
      "Epoch 49\n",
      " Epoch: 49  Batch:  50 / 381  loss: 5.4967  Average batch time: 0.390 secs\n",
      " Epoch: 49  Batch: 100 / 381  loss: 5.4954  Average batch time: 0.394 secs\n",
      " Epoch: 49  Batch: 150 / 381  loss: 5.4969  Average batch time: 0.394 secs\n",
      " Epoch: 49  Batch: 200 / 381  loss: 5.4986  Average batch time: 0.396 secs\n",
      " Epoch: 49  Batch: 250 / 381  loss: 5.4979  Average batch time: 0.399 secs\n",
      " Epoch: 49  Batch: 300 / 381  loss: 5.4979  Average batch time: 0.399 secs\n",
      " Epoch: 49  Batch: 350 / 381  loss: 5.4979  Average batch time: 0.402 secs\n",
      "\n",
      "Training loss: 5.497971\n",
      "Time elapsed: 137.1 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4980\n",
      "Epoch 50\n",
      " Epoch: 50  Batch:  50 / 381  loss: 5.4948  Average batch time: 0.418 secs\n",
      " Epoch: 50  Batch: 100 / 381  loss: 5.4976  Average batch time: 0.419 secs\n",
      " Epoch: 50  Batch: 150 / 381  loss: 5.4984  Average batch time: 0.418 secs\n",
      " Epoch: 50  Batch: 200 / 381  loss: 5.4982  Average batch time: 0.419 secs\n",
      " Epoch: 50  Batch: 250 / 381  loss: 5.4973  Average batch time: 0.423 secs\n",
      " Epoch: 50  Batch: 300 / 381  loss: 5.4975  Average batch time: 0.426 secs\n",
      " Epoch: 50  Batch: 350 / 381  loss: 5.4981  Average batch time: 0.428 secs\n",
      "\n",
      "Training loss: 5.498096\n",
      "Time elapsed: 139.8 minutes.\n",
      "Validating...\n",
      "Validation loss: 5.4982\n",
      "Finished Training. Total time: 139.91583964824676 minutes.\n",
      "Best validation loss: 5.497, achieved on epoch #29\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('',\n",
       " [5.498477426413789,\n",
       "  5.498279093444504,\n",
       "  5.4986032488465,\n",
       "  5.499214336315165,\n",
       "  5.499398118867649,\n",
       "  5.498792453075018,\n",
       "  5.499017644116259,\n",
       "  5.498720927501288,\n",
       "  5.498701951635166,\n",
       "  5.499545062307924,\n",
       "  5.499411454038044,\n",
       "  5.498501533598412,\n",
       "  5.498587627110519,\n",
       "  5.4990555683146,\n",
       "  5.498524066344333,\n",
       "  5.498778050340067,\n",
       "  5.498441530963567,\n",
       "  5.498613105984185,\n",
       "  5.498935240147308,\n",
       "  5.498999226437466,\n",
       "  5.498510918905103,\n",
       "  5.499040899001394,\n",
       "  5.49868155902452,\n",
       "  5.498393272790383,\n",
       "  5.4987032069308865,\n",
       "  5.499116348156466,\n",
       "  5.4985579743472925,\n",
       "  5.498866111274779,\n",
       "  5.4985206959441575,\n",
       "  5.498425381077244,\n",
       "  5.499184032750568,\n",
       "  5.498910935219191,\n",
       "  5.498574325731733,\n",
       "  5.4983995342504945,\n",
       "  5.498048605881338,\n",
       "  5.498845490883655,\n",
       "  5.498345997076961,\n",
       "  5.498569835202274,\n",
       "  5.499395076371241,\n",
       "  5.498775581049481,\n",
       "  5.498719729776457,\n",
       "  5.498612881958328,\n",
       "  5.498209779343893,\n",
       "  5.498352359911901,\n",
       "  5.498886808009911,\n",
       "  5.498023391082844,\n",
       "  5.498608167403013,\n",
       "  5.498053352976721,\n",
       "  5.497970515974551,\n",
       "  5.498095999239624],\n",
       " [5.498618188111679,\n",
       "  5.498626087022864,\n",
       "  5.498690563699474,\n",
       "  5.498658097308615,\n",
       "  5.498955540035082,\n",
       "  5.498517492543096,\n",
       "  5.498597020688265,\n",
       "  5.498645181241243,\n",
       "  5.498742953590725,\n",
       "  5.498825093974238,\n",
       "  5.498777824899425,\n",
       "  5.498773035795792,\n",
       "  5.498712104299794,\n",
       "  5.498451875603718,\n",
       "  5.498405829719875,\n",
       "  5.498515502266262,\n",
       "  5.498588955920676,\n",
       "  5.49870084679645,\n",
       "  5.498629404150921,\n",
       "  5.498303517051365,\n",
       "  5.498533767202626,\n",
       "  5.498276275137196,\n",
       "  5.49885428470114,\n",
       "  5.4986958503723145,\n",
       "  5.49833399316539,\n",
       "  5.498135214266569,\n",
       "  5.498513781506082,\n",
       "  5.4978928565979,\n",
       "  5.497419460960057,\n",
       "  5.497954824696416,\n",
       "  5.497882075931715,\n",
       "  5.497752023779827,\n",
       "  5.4984224775563115,\n",
       "  5.497880355171535,\n",
       "  5.497704733972964,\n",
       "  5.497672288314156,\n",
       "  5.498116970062256,\n",
       "  5.498358498448911,\n",
       "  5.4985699031663975,\n",
       "  5.498314007468846,\n",
       "  5.498070468073306,\n",
       "  5.497927188873291,\n",
       "  5.4980083548504375,\n",
       "  5.497620002083156,\n",
       "  5.497759487317956,\n",
       "  5.497735956440801,\n",
       "  5.497616539830747,\n",
       "  5.497717463451883,\n",
       "  5.498025624648385,\n",
       "  5.498216960741126],\n",
       " [])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(model, train_loader, valid_loader, criterion, optimizer, scheduler=None, num_epochs=EPOCHS, save_freq=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf03c3a-daa0-47bc-85b0-b555bceeb97b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
