{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28eba9b2-d896-4544-8dfe-c40dcd627bb1",
   "metadata": {},
   "source": [
    "# First text experimental model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f280fb-df01-4d3f-b418-d9ee7ed50c8f",
   "metadata": {},
   "source": [
    "This notebook contains a first attempt to create a model for the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92419d8d-7f91-4c33-9f45-53fe9c0434b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd3ae77b-aa0c-48b9-badb-849401aeaa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pyarrow.parquet as pq\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import pytorch_lightning as pl\n",
    "from sklearn import *\n",
    "from torchmetrics.classification import accuracy\n",
    "\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e4491c-e425-47a5-8cc2-b172e4cdc807",
   "metadata": {},
   "source": [
    "Now that we have a seperate class for the data, we can just load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7852a95-473b-4af5-810f-4f8c7e6ef276",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS_TO_USE = [\"x\",\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3ef0f7f-a2f2-41de-88fc-4f770ca10e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASL_DATSET(Dataset):\n",
    "    def __init__(self, transform=None, max_seq_length=MAX_SEQUENCES,):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.transform = transform\n",
    "        \n",
    "        \n",
    "        #[TODO] get this from data\n",
    "        self.max_seq_length = max_seq_length\n",
    "        \n",
    "        self.n_features =  HAND_FEATURES *2 + 12 + len(FACE_INDICES)\n",
    "        \n",
    "        self.total_length = self.max_seq_length * self.n_features\n",
    "        self.load_data()\n",
    "        \n",
    "    def load_data(self):\n",
    "        \n",
    "        # Load Processed data\n",
    "        self.df_train = pd.read_csv(os.path.join(ROOT_PATH,RAW_DATA_DIR,\"train.csv\"))\n",
    "        self.label_dict =  json.load(open(os.path.join(ROOT_PATH,RAW_DATA_DIR,MAP_JSON_FILE)))\n",
    "        \n",
    "        # Generate Absolute path to locate landmark files\n",
    "        self.file_paths = np.array([os.path.join(ROOT_PATH,RAW_DATA_DIR,x) for x in self.df_train[\"path\"].values])\n",
    "        self.labels = self.df_train.sign.map(self.label_dict).values\n",
    "        \n",
    "        # Store individual metadata lists\n",
    "        # [TODO] Cleanup unnecessary files, do we need these?\n",
    "        self.participant_ids = self.df_train[\"participant_id\"].values\n",
    "        self.sequence_ids = self.df_train[\"sequence_id\"].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df_train)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.item()\n",
    "        \n",
    "        # Get the processed data for the single index\n",
    "        landmark_path = self.file_paths[idx]\n",
    "        target = self.labels[idx]\n",
    "        \n",
    "        # Read in the processed file\n",
    "        df_in = pd.read_parquet(landmark_path).fillna(0)\n",
    "        \n",
    "        #get number of frames\n",
    "        n_frames = df_in.frame.nunique()\n",
    "\n",
    "        \n",
    "        #select the landmarks\n",
    "        landmarks = df_in.loc[(\n",
    "                    ((df_in.type == \"pose\")&(df_in.landmark_index.isin(list(range(11,23)))))|\n",
    "\n",
    "                   ( (df_in.type == \"face\")&(df_in.landmark_index.isin(FACE_INDICES)))|\n",
    "                    ((df_in.type == \"right_hand\"))|\n",
    "                    ((df_in.type == \"left_hand\"))\n",
    "                ),COLUMNS_TO_USE\n",
    "        ].values\n",
    "\n",
    "         \n",
    "\n",
    "        #print(n_frames)\n",
    "        #pad or crop series to max_seq_length\n",
    "        if n_frames <= self.max_seq_length:\n",
    "            landmarks = np.append(landmarks,np.zeros(((MAX_SEQUENCES-n_frames)*self.n_features,2)),axis = 0)\n",
    "        else:\n",
    "            #crop\n",
    "            landmarks = landmarks[:self.total_length,:]\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #landmark_file = torch.load(landmark_file)\n",
    "\n",
    "        \n",
    "        # Get the processed landmarks and target for the data\n",
    "        # landmarks = landmark_file['landmarks']\n",
    "        # target = landmark_file['target']\n",
    "        # size = landmark_file['size']\n",
    "        \n",
    "        # Pad the landmark data\n",
    "        # pad_len = max(0, self.max_seq_length - len(landmarks))\n",
    "        # landmarks = landmarks + [[0]*len(landmarks[0])] * pad_len\n",
    "        \n",
    "        # if self.transform:\n",
    "         #    sample = self.transform(landmarks)\n",
    "            \n",
    "        #create tensor\n",
    "        lm = torch.from_numpy(landmarks).reshape(self.max_seq_length,self.n_features*2)\n",
    "      \n",
    "        \n",
    "        return {'landmarks': lm, 'target': torch.Tensor([target])}\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'ASL_DATSET(Participants: {len(set(self.participant_ids))}, Length: {len(self.df_train)}, Number of Features: {self.n_features}, \" Number of Frames: {self.max_seq_length}\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "380ac139-718f-480e-b380-6241d3ec48a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dL = DataLoader(ASL_DATSET(),shuffle = True,batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6b2e7a6-e46f-40eb-b4ee-a53af648341a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 537, 188])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dL))[\"landmarks\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da19c45d-dedd-4619-9992-3db0b573d5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ASL_DATSET()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2679ac29-7050-4e5e-a711-dee983b7b39a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'landmarks': tensor([[0.4768, 0.4567, 0.4794,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.4794, 0.4544, 0.4819,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.4795, 0.4549, 0.4821,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "        dtype=torch.float64),\n",
       " 'target': tensor([50.])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc15c2a3-6c4d-4c06-a400-ab991c26d803",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 543)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20a0858a-1362-4d3c-be24-c96c07770061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'landmarks': tensor([[0.4944, 0.3805, 0.4983,  ..., 0.3996, 0.3858, 0.4011],\n",
       "         [0.5012, 0.3806, 0.5033,  ..., 0.3803, 0.4164, 0.3829],\n",
       "         [0.4985, 0.3795, 0.5016,  ..., 0.3777, 0.4391, 0.3799],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "        dtype=torch.float64),\n",
       " 'target': tensor([25.])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57eb07a7-7c71-4986-847e-76eceeecba0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x2e6270e11f0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SEQUENCES = 150\n",
    "dataset = DataLoader(ASL_DATSET(),shuffle = True,batch_size = 32)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cce59fa0-aefe-424c-a90a-4200186f92b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[537, 188]' is invalid for input of size 28200",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimeit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msample = next(iter(dataset))\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\CASAML\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2430\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2428\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m   2429\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[1;32m-> 2430\u001b[0m     result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2432\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[0;32m   2433\u001b[0m \u001b[38;5;66;03m# when using magics with decodator @output_can_be_silenced\u001b[39;00m\n\u001b[0;32m   2434\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[0;32m   2435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\CASAML\\lib\\site-packages\\IPython\\core\\magics\\execution.py:1164\u001b[0m, in \u001b[0;36mExecutionMagics.timeit\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1162\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m   1163\u001b[0m     number \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m index\n\u001b[1;32m-> 1164\u001b[0m     time_number \u001b[38;5;241m=\u001b[39m \u001b[43mtimer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m time_number \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m:\n\u001b[0;32m   1166\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\CASAML\\lib\\site-packages\\IPython\\core\\magics\\execution.py:158\u001b[0m, in \u001b[0;36mTimer.timeit\u001b[1;34m(self, number)\u001b[0m\n\u001b[0;32m    156\u001b[0m gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 158\u001b[0m     timing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gcold:\n",
      "File \u001b[1;32m<magic-timeit>:1\u001b[0m, in \u001b[0;36minner\u001b[1;34m(_it, _timer)\u001b[0m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\CASAML\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\CASAML\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    677\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 678\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    680\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\CASAML\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\CASAML\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[4], line 90\u001b[0m, in \u001b[0;36mASL_DATSET.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     68\u001b[0m     landmarks \u001b[38;5;241m=\u001b[39m landmarks[:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_length,:]\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m#landmark_file = torch.load(landmark_file)\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \n\u001b[0;32m     76\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     88\u001b[0m     \n\u001b[0;32m     89\u001b[0m \u001b[38;5;66;03m#create tensor\u001b[39;00m\n\u001b[1;32m---> 90\u001b[0m lm \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlandmarks\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_features\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlandmarks\u001b[39m\u001b[38;5;124m'\u001b[39m: lm, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m: torch\u001b[38;5;241m.\u001b[39mTensor([target])}\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[537, 188]' is invalid for input of size 28200"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "sample = next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef391a62-b8b9-4109-9637-5692d9dfd656",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d40e61f-084f-4b1a-8793-c7933e381a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[\"landmarks\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0222abbe-4f7f-49e8-ac42-1c3f42c9c2df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52.513966480446925"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28200/537"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adbd2e8-141d-41d5-858f-2544ce51e371",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[\"landmarks\"][::2,0].shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9fbc91-b603-415d-a606-990d7efef152",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5d7155-22f6-47bd-af21-63c0be69618b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASLDataModule(pl.LightningDataModule):\n",
    "    def __init__(self,batch_size = 16,num_workers = 0):\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        \n",
    "      \n",
    "        \n",
    "    def prepare_data(self):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = ASL_DATSET()\n",
    "        \n",
    "    \n",
    "    def train_dataloader(self):   \n",
    "        \n",
    "        train_loader = DataLoader(self.train_dataset, \n",
    "                                  batch_size = self.batch_size, \n",
    "                                  shuffle = True, \n",
    "                                  num_workers = self.num_workers)\n",
    "        \n",
    "        return train_loader\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return None\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f884db-66c2-49ae-ac0d-fb64c4d9fb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dM = ASLDataModule()\n",
    "dM.setup()\n",
    "train_loader = dM.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6e2581-7897-4167-aea0-15bee25cfad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(train_loader))\n",
    "sample[\"landmarks\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3742f64d-bdf0-4518-9938-145166b65a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LSTM_Model(nn.Module):\n",
    "    def __init__(self,n_features, n_classes = 250,n_hidden = 256 ,num_layers =3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size = n_features,\n",
    "            hidden_size = n_hidden,\n",
    "            num_layers = num_layers,\n",
    "            batch_first = True,\n",
    "            dropout = .3)\n",
    "        \n",
    "        self.fc = nn.Linear(n_features,n_classes)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        self.lstm.flatten_parameters()\n",
    "        _, (hidden,_) = self.lstm(x)\n",
    "        \n",
    "        out = hidden[-1]\n",
    "        \n",
    "        return self.fc(out)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086fa925-d01c-4423-b6a8-5b4dafce998d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d318fc2-3e7b-49e1-bd4d-d3782e8b01a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728d0be6-81d6-4b22-a9da-715b9e2759ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Predictor(pl.LightningModule):\n",
    "    def __init__(self, \n",
    "                 n_features: int, \n",
    "                 n_classes:int = 250, \n",
    "                 num_layers:int = 3):\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        self.model = LSTM_Model(n_features = n_features,\n",
    "                                n_classes = n_classes, \n",
    "                                num_layers = num_layers)\n",
    "        #Define criterion\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        \n",
    "                \n",
    "        self.accuracy = accuracy.Accuracy(task = \"multiclass\",\n",
    "                                          num_classes=n_classes\n",
    "                                     )\n",
    "        \n",
    "    def forward(self,x,labels):\n",
    "        y_hat = self.model(x)\n",
    "        loss = 0\n",
    "        if labels is not None:\n",
    "            loss = self.criterion(y_hat,labels)\n",
    "        return loss, y_hat\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        landmarks = batch[\"landmarks\"]\n",
    "        labels = batch[\"target\"]\n",
    "        \n",
    "        #forward pass through the model\n",
    "        loss, out = self(landmarks,labels)\n",
    "        y_hat = torch.argmax(out,dim = 1)\n",
    "        step_accuracy = self.accuracy(y_hat,labels)\n",
    "        \n",
    "        \n",
    "        self.log(\"train_loss\", loss, prog_bar = True, logger = True)\n",
    "        self.log(\"train_accuracy\", step_accuracy, prog_bar = True, logger = True)\n",
    "        return {\"loss\":loss, \"train_accuracy\":step_accuracy}\n",
    "        \n",
    "        \n",
    "    def validation_step(self,batch,batch_idx):\n",
    "        pass\n",
    "        \n",
    "        \n",
    "    def configure_optimizers(self,):\n",
    "        return torch.optim.Adam(self.parameters(), lr = 0.0001)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6c60a7-6655-4e78-9ba6-99f2b719c63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the model\n",
    "model = LSTM_Predictor(n_features=188,num_layers = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36319285-2119-4af4-bcc7-b079a157e5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./../checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92afdc43-574b-4d9b-b33b-2056300c7ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath = os.path.join(ROOT_PATH,\"checkpoints\"),\n",
    "        filename = \"best_checkpoint\",\n",
    "    save_top_k = 1,\n",
    "    monitor = \"train_loss\",\n",
    "    verbose = True,\n",
    "    mode = \"min\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee8e72b0-5619-4283-95ac-df9cb3954044",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_logger = TensorBoardLogger(save_dir = os.path.join(ROOT_PATH,\"checkpoints\"),\n",
    "                              name = \"lightning_logs\"\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eaa11ff4-2a01-434d-a6dd-9897959e45dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(accelerator = \"gpu\",\n",
    "                     logger = tb_logger,\n",
    "                     callbacks=[checkpoint_callback],\n",
    "                     max_epochs=250,\n",
    "                     \n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78839f88-1a5d-4351-a757-5d2db96cd963",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainer\u001b[38;5;241m.\u001b[39mfit(model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m,\n\u001b[0;32m      2\u001b[0m             datamodule\u001b[38;5;241m=\u001b[39mdM\n\u001b[0;32m      3\u001b[0m        )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "trainer.fit(model = model,\n",
    "            datamodule=dM\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e704f3-73b7-42dd-b472-6a204841e6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmark_path = dataset.file_paths[0]\n",
    "        \n",
    "COLUMNS_TO_USE = [\"x\",\"y\"]\n",
    "\n",
    "\n",
    "# Read in the processed file\n",
    "df_in = pd.read_parquet(landmark_path).fillna(0)\n",
    "\n",
    "#get number of frames\n",
    "n_frames = df_in.frame.nunique()\n",
    "\n",
    "\n",
    "landmarks = df_in.loc[df_in.landmark_index.isin(LANDMARK_INDICES)][COLUMNS_TO_USE].values\n",
    "print(landmarks.shape)\n",
    "\n",
    "#pad or crop series to max_seq_length\n",
    "if n_frames <= dataset.max_seq_length:\n",
    "    landmarks = np.append(landmarks,np.zeros(((MAX_SEQUENCES-n_frames+1)*len(LANDMARK_INDICES),2)),axis = 0)\n",
    "else:\n",
    "    #crop\n",
    "    landmarks = landmarks[:dataset.total_length,:]\n",
    "landmarks.shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869062a4-e9d3-460a-bb7f-28b198b7357b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in.loc[df_in.frame == 20];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3306c0e7-5d8c-4f58-89ca-58e622391940",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "#selection of landmarks\n",
    "dataset = ASL_DATSET()\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106ea486-df07-4223-b8c8-1b5927fea823",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(FACE_INDICES) + HAND_FEATURES *2 + 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b363074-9db7-406f-9a2d-47d1494df634",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(LANDMARK_INDICES) * MAX_SEQUENCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424669d0-5c34-4556-9d65-ab9fcb9c3116",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(LANDMARK_INDICES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e389bbb7-a190-4a0e-be98-ee55329b970c",
   "metadata": {},
   "outputs": [],
   "source": [
    "39201 - (MAX_SEQUENCES - n_frames)*len(LANDMARK_INDICES) + 1196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8dfefd-d325-4653-a3cd-0c0b44937e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f484df-ba35-4a56-943e-2f553fee2338",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames = df_in.frame.nunique()\n",
    "n_frames\n",
    "np.zeros(((MAX_SEQUENCES-n_frames)*len(LANDMARK_INDICES),2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596b13a4-2b9c-4d61-a4e7-8e9d092e918c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCES * (len(LANDMARK_INDICES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c671e5b0-7a14-4f6b-8422-a63e274baf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in.loc[df_in.frame == 20];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d7ad31-1e58-4e76-a3e9-a23c29dd5718",
   "metadata": {},
   "outputs": [],
   "source": [
    "LANDMARK_INDICES\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f085d7d3-369a-4bfd-8e28-fec238640077",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ba6f6a-4028-4c1a-a291-5590b540b022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00e56f1-9782-45dd-b495-699ab6c496db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70093e6-f708-4a99-99aa-ea8dd485031e",
   "metadata": {},
   "source": [
    "Get dataloader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f5fc53-6079-4403-bb17-80d71fe4f951",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = ASLDataModule(batch_size = 16)\n",
    "dm.setup()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
